{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import importlib\n",
    "import pickle\n",
    "\n",
    "import models\n",
    "import DataLoader\n",
    "import utils\n",
    "import main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(DataLoader)\n",
    "# features = ['chid', 'masts', 'educd', 'trdtp', 'poscd', 'gender_code',\n",
    "#                'age', 'label1', 'label2', 'label3', 'tx1', 'tx2', 'tx3']\n",
    "path = './dataset/user_features4/'\n",
    "train_idxs = torch.arange(0, 500000)\n",
    "data_loader = DataLoader.dataLoader(path, train_idxs, batch_size=10000, train=True)\n",
    "# data_loader = DataLoader.DataSet(path, train_idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features\n",
    "masts = [0., 1., 2., 3.]\n",
    "educd = [0., 1., 2., 3., 4., 5., 6.]\n",
    "trdtp = [0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,\n",
    "       13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25.,\n",
    "       26., 27., 28., 29.]\n",
    "poscd = [ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 99.]\n",
    "gender_code = [0., 1.]\n",
    "age = [0., 1., 2., 3., 4., 5., 6., 7., 8., 9.]\n",
    "labels = [0, 2, 6, 10, 12, 13, 15, 18, 19, 21, 22, 25, 26, 36, 37, 39, 48]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(models)\n",
    "epochs = 300\n",
    "lr = 0.001\n",
    "var1 = 0.9\n",
    "var2 = 0.999\n",
    "savePath ='./models/checkpoints.pt'\n",
    "# weight = torch.tensor([0.0020, 0.0242, 0.0765, 0.0206, 0.0453, 0.1016, 0.0199, 0.0882, 0.0463,\n",
    "#           0.1176, 0.1164, 0.0860, 0.1119, 0.0216, 0.0109, 0.0836, 0.0273])\n",
    "weight = None\n",
    "\n",
    "featureType = {'Qn': 16, 'Qn_dim':23,\n",
    "               'Ql':[len(masts), len(educd), len(trdtp), len(poscd), len(gender_code), len(age), len(labels), len(labels), len(labels)],\n",
    "               'Ql_dim':23\n",
    "              }\n",
    "modelType = {'hidden_dim':100, 'layer_num':5, 'output_dim': 17, 'topN': 3, 'weight': weight, 'bias':True}\n",
    "\n",
    "logger = utils.create_logger('./models/', 'logger.txt')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu' )\n",
    "LSTM = models.LSTMModel(featureType, modelType, device=device).to(device)\n",
    "optimizer = optim.Adam(LSTM.parameters(), betas=[var1, var2], lr=lr)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-03 16:47:34,534 INFO epoch: 1/300, trainLoss: 8.223831014633179, valLoss: 8.28961009979248\n",
      "2022-01-03 16:48:23,331 INFO epoch: 2/300, trainLoss: 7.594730043411255, valLoss: 7.867662124633789\n",
      "2022-01-03 16:49:11,975 INFO epoch: 3/300, trainLoss: 7.534705028533936, valLoss: 7.820180158615113\n",
      "2022-01-03 16:50:01,615 INFO epoch: 4/300, trainLoss: 7.494595947265625, valLoss: 7.779039058685303\n",
      "2022-01-03 16:50:50,276 INFO epoch: 5/300, trainLoss: 7.471688241958618, valLoss: 7.756323719024659\n",
      "2022-01-03 16:51:39,567 INFO epoch: 6/300, trainLoss: 7.460184698104858, valLoss: 7.743845653533936\n",
      "2022-01-03 16:52:29,349 INFO epoch: 7/300, trainLoss: 7.4548015308380124, valLoss: 7.7383527755737305\n",
      "2022-01-03 16:53:18,841 INFO epoch: 8/300, trainLoss: 7.452145328521729, valLoss: 7.735686798095703\n",
      "2022-01-03 16:54:08,258 INFO epoch: 9/300, trainLoss: 7.4499032688140865, valLoss: 7.73334677696228\n",
      "2022-01-03 16:54:57,869 INFO epoch: 10/300, trainLoss: 7.44885443687439, valLoss: 7.732296438217163\n",
      "2022-01-03 16:55:46,440 INFO epoch: 11/300, trainLoss: 7.447155456542969, valLoss: 7.730445108413696\n",
      "2022-01-03 16:56:35,795 INFO epoch: 12/300, trainLoss: 7.446364755630493, valLoss: 7.7296053981781006\n",
      "2022-01-03 16:57:24,353 INFO epoch: 13/300, trainLoss: 7.445621786117553, valLoss: 7.728972053527832\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-5c62e0e0bbf2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     models.train(LSTM, optimizer, data_loader, device=device, epochs=epochs, savePath=savePath,\n\u001b[0;32m----> 3\u001b[0;31m                  featureType=featureType, modelType=modelType, logger=logger)\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"something raised an exception: {}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/soa3/graph_learning/TBrainAI/models.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, data_loader, device, epochs, savePath, featureType, modelType, logger, re_epochs)\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainLabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mtrainLoss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "try:\n",
    "    models.train(LSTM, optimizer, data_loader, device=device, epochs=epochs, savePath=savePath,\n",
    "                 featureType=featureType, modelType=modelType, logger=logger)\n",
    "except Exception as e:\n",
    "    logger.warning(\"something raised an exception: {}\", exc_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model for train\n",
    "importlib.reload(models)\n",
    "modelPath = './models/checkpoints_hoo.pt'\n",
    "savePath ='./models/checkpoints.pt'\n",
    "\n",
    "epochs = 500\n",
    "lr = 0.001\n",
    "var1 = 0.9\n",
    "var2 = 0.999\n",
    "checkpoint = torch.load(modelPath, map_location=torch.device('cpu'))\n",
    "\n",
    "re_epochs = checkpoint['epochs']\n",
    "featureType = checkpoint['featureType']\n",
    "modelType = checkpoint['modelType']\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu' )\n",
    "\n",
    "logger = utils.create_logger('./models/', 'logger.txt')\n",
    "LSTM = models.LSTMModel(featureType, modelType, device=device).to(device)\n",
    "optimizer = optim.Adam(LSTM.parameters(), betas=[var1, var2], lr=lr)\n",
    "LSTM.load_state_dict(checkpoint['model'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-27 13:19:30,087 INFO epoch: 301/500, trainLoss: 7.451547145843506, valLoss: 7.254924297332764\n",
      "2021-12-27 13:20:11,083 INFO epoch: 302/500, trainLoss: 7.45157642364502, valLoss: 7.254914093017578\n",
      "2021-12-27 13:20:51,886 INFO epoch: 303/500, trainLoss: 7.451534414291382, valLoss: 7.25483512878418\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    models.train(LSTM, optimizer, data_loader, device=device, epochs=epochs, savePath=savePath,\n",
    "                 featureType=featureType, modelType=modelType, logger=logger, re_epochs=re_epochs)\n",
    "except Exception as e:\n",
    "    logger.warning(\"something raised an exception: {}\", exc_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs 測試\n",
    "for x, label in data_loader:\n",
    "    inputs = x[:, :, 1:-3]\n",
    "    outputs = LSTM(inputs)\n",
    "    loss = LSTM.loss_fun(outputs, label)\n",
    "    loss.backward()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([116, 3])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSTM.QlV.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10000, 23, 17]), torch.Size([10000, 23, 3]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape, label.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features\n",
    "masts = [0., 1., 2., 3.]\n",
    "educd = [0., 1., 2., 3., 4., 5., 6.]\n",
    "trdtp = [0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,\n",
    "       13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25.,\n",
    "       26., 27., 28., 29.]\n",
    "poscd = [ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 99.]\n",
    "gender_code = [0., 1.]\n",
    "age = [0., 1., 2., 3., 4., 5., 6., 7., 8., 9.]\n",
    "labels = [0, 2, 6, 10, 12, 13, 15, 18, 19, 21, 22, 25, 26, 36, 37, 39, 48]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test loader\n",
    "importlib.reload(DataLoader)\n",
    "path = './dataset/user_features2/'\n",
    "idxs = torch.arange(0, 500000)\n",
    "data_loader = DataLoader.dataLoader(path, idxs, batch_size=10000, train=False, shuffle=False)\n",
    "# data_loader = DataLoader.DataSet(path, train_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(models)\n",
    "savePath ='./models/checkpoints.pt'\n",
    "checkpoint = torch.load('./models/checkpoints.pt', map_location=torch.device('cpu'))\n",
    "\n",
    "featureType = checkpoint['featureType']\n",
    "modelType = checkpoint['modelType']\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu' )\n",
    "\n",
    "LSTM = models.LSTMModel(featureType, modelType, device=device).to(device)\n",
    "LSTM.load_state_dict(checkpoint['model'])\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "idx = []\n",
    "for inputs in data_loader:\n",
    "    with torch.no_grad():\n",
    "        idx.append(inputs[:, 0:1, 0])\n",
    "        \n",
    "        inputs = inputs[:, :, 1:-3]\n",
    "        outputs = LSTM(inputs)[:, -1, :]\n",
    "        result.append(outputs)\n",
    "\n",
    "result = torch.cat(result, dim=0).numpy()\n",
    "idx = torch.cat(idx, dim=0).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'result': result, 'idx': idx}\n",
    "with open('./result/result1.pickle', 'wb') as f:\n",
    "    pickle.dump(d, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = c[:, 1:].argsort(dim=1, descending=True) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  3,  6, 13, 14, 16])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f[:, :3].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  3,  6, 13, 14, 16])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.argsort(dim=1, descending=True)[:, :4].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val\n",
    "result = []\n",
    "l = []\n",
    "for inputs, label in data_loader:\n",
    "    with torch.no_grad():\n",
    "        inputs = inputs[:, :, 1:]\n",
    "        outputs = LSTM(inputs)[:, -1, :]\n",
    "    \n",
    "        result.append(outputs)\n",
    "        l.append(label[:, -1, :])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[16, 14, 13],\n",
       "        [14, 16, 13],\n",
       "        [14, 16, 13],\n",
       "        ...,\n",
       "        [13, 14, 16],\n",
       "        [14, 13, 16],\n",
       "        [14, 13, 16]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff = result[0][:, 1:].argsort(dim=1, descending=True)[:, :3] + 1\n",
    "ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([16, 14, 14,  ..., 13, 14, 14])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1 = ff[:, 0]\n",
    "c1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([16., 14.,  1.,  ..., 13.,  0.,  0.])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2 = l[0][:, 0].reshape(-1).type(torch.float)\n",
    "c2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3255.)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((c1 == c2) + 0.).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 3, 4])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.empty(3, dtype=torch.long).random_(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100, 23, 10]), torch.Size([100, 23, 3]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, (x, label) in enumerate(data_loader):\n",
    "    break\n",
    "x.shape, label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x[:, :, 1:]\n",
    "outputs = LSTM(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3, 13,  0,  ..., 18,  3, 18],\n",
       "        [ 2, 21,  1,  ..., 17,  2, 17],\n",
       "        [ 4, 14,  2,  ..., 20,  4, 16],\n",
       "        ...,\n",
       "        [21,  2, 13,  ...,  2, 21,  2],\n",
       "        [22,  1, 17,  ...,  1, 22,  1],\n",
       "        [ 0,  0, 16,  ...,  0,  0,  0]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.argsort(dim=1, descending=True).reshape(-1, 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 0, 3])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.empty(3, dtype=torch.long).random_(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(12).reshape(3, 4)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 1],\n",
       "         [4, 5],\n",
       "         [8, 9]]),\n",
       " tensor([[ 2,  3],\n",
       "         [ 6,  7],\n",
       "         [10, 11]]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.chunk(3, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(15)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(5 * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9999])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tanh(torch.tensor([5]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
